{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "quantitative-bracelet",
   "metadata": {},
   "source": [
    "# Detecção de leucemia baseado em imagens de leucócitos\n",
    "\n",
    "Este projeto foi desenvolvido para o trabalho final da disciplina Visão Computacional, ministrada pelo Prof. Dr. Lucas Ferrari de Oliveira para o curso de Especialização em Inteligência Artificial Aplicada na Universidade Federal do Paraná.\n",
    "\n",
    "#### Descrição do trabalho\n",
    "\n",
    "O arquivo trabalho.zip possui imagens de leucócitos na parte central. As imagens são nomeadas como \"ImXXX_Y_Z.jpg\". Onde ImXXX é o número da imagem, Y é o seu número da sequência de alteração (data augmentation) e Z a sua classe (0 ou 1). Onde, 0 indica paciente normal e 1 pacientes com leucemia.\n",
    "\n",
    "Utilizando técnicas de Visão Computacional e/ou CNNS extraia características das imagens e faça a sua correta classificação (0 ou 1). Lembre-se de separar os grupos de treinamento e teste. Você pode utilizar a técnica de k-folds para a divisão das imagens e evitar o overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-suggestion",
   "metadata": {},
   "source": [
    "### Passos para rodar o código\n",
    "\n",
    "É necessário ter um ambiente Python configurado em sua máquina para executar o código. Ele foi desenvolvido no Python 3.8, logo essa é a versão mais recomendada para a execução.\n",
    "\n",
    "<b> Além do ambiente Python dê preferência por executar este Notebook no Jupyter Labs. Executando no Jupyter Notebooks a saída do console aparecerá apenas no seu terminal Python e não no Notebook. </b>\n",
    "\n",
    "Além do ambiente serão necessárias algumas bibliotecas para o código:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;- Numpy (https://numpy.org/) (1.19.0)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;- OpenCV (https://opencv.org/) (4.5.1.48)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;- Tensorflow (https://www.tensorflow.org/) (2.2)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;- Keras (https://keras.io/) (2.3.1)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;- ScyPy (https://www.scipy.org/) (1.6.0)<br>\n",
    "    \n",
    "Caso seja necessário posso passar meu ambiente venv do PyCharm com estes pacotes já instalados.\n",
    "\n",
    "A estrutura de pastas das imagens deve estar na seguinte hierarquia: <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;- Raiz <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- AugmentedImages <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Images <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- ModifiedAugmentedImages <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- ModifiedImages <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Leukemia <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Normal <br>\n",
    "\n",
    "Além disso o código deve estar na pasta raiz para que seja executado corretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-attack",
   "metadata": {},
   "source": [
    "<b> Instalação das bibliotecas no terminal Python (PIP) </b><br>\n",
    "pip install numpy <br>\n",
    "pip install opencv-python <br>\n",
    "pip install tensorflow <br>\n",
    "pip install matplotlib <br>\n",
    "pip install SciPy <br>\n",
    "\n",
    "<b> Instalação das bibliotecas em ambiente Conda (Não testado) </b><br>\n",
    "conda install numpy <br>\n",
    "conda install -c menpo opencv <br>\n",
    "conda create -n tf tensorflow <br>\n",
    "conda activate tf <br>\n",
    "conda install -c anaconda scipy <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-romania",
   "metadata": {},
   "source": [
    "## Apresentação do código"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-bottom",
   "metadata": {},
   "source": [
    "Inicialmente é necessário importar todos os pacotes que serão usados dentro do código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "demographic-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image as kerasImage\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-violin",
   "metadata": {},
   "source": [
    "Então é criada uma classe para guardar os dados das imagens, como a imagem em questão, seu nome de arquivo e seu tipo, sendo 1 representando o leucócito com leucemia e 0 para o leucócito normal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hairy-weather",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image:\n",
    "    img = None\n",
    "    name = ''\n",
    "    type = ''\n",
    "\n",
    "    def __init__(self, name, img, type):\n",
    "        self.name = name\n",
    "        self.img = img\n",
    "        self.type = type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-mobile",
   "metadata": {},
   "source": [
    "Com a classe criada agora é possível criar uma função que leia um diretório, pegue as imagens, seus nomes de arquivo e dentro do nome do arquivo extraia o tipo certo de cada imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "interesting-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(folder):\n",
    "    print(\"Loading images...\")\n",
    "    pictures = []\n",
    "    for filename in enumerate(os.listdir(folder)):\n",
    "        pictures.append(Image(filename[1], cv2.imread(os.path.join(folder, filename[1])), filename[1][-5]))\n",
    "    return pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-fishing",
   "metadata": {},
   "source": [
    "Tendo uma lista de imagens é possível processá-las e guardá-las em outro diretório para usá-las futuramente para a execução do treinamento. Para este processamento foi aplicado um borrão gaussiano leve para diminuir o ruído da imagem, e então foi aplicado um limite simples binário invertido. Este limite é aplicado em toda a imagem, com isso se o pixel for menor que o limite, o mesmo é passado para o valor máximo, do contrário é passado para zero. Então essa imagem binária é guardada como uma máscara e aplicada em cima da imagem original, visando isolar apenas o leucócito na parte central. Feito isso as imagens são separadas em duas pastas diferentes uma para os casos normais e outra para os casos de leucemia. É separado dessa forma para que mais adiante seja possível separar em classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "conceptual-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save(folder, pictures):\n",
    "    print(\"Processing and saving images...\")\n",
    "    for index, image in enumerate(pictures):\n",
    "        img = cv2.cvtColor(image.img, cv2.COLOR_BGR2GRAY)\n",
    "        suave = cv2.GaussianBlur(img, (7, 7), 0)\n",
    "        (T, binI) = cv2.threshold(suave, 105, 255, cv2.THRESH_BINARY_INV)\n",
    "        subfolder = folder + 'Leukemia/' if image.type == '1' else folder + 'Normal/'\n",
    "        cv2.imwrite(subfolder + image.name,\n",
    "                    cv2.bitwise_and(img, img, mask=binI))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-material",
   "metadata": {},
   "source": [
    "Além das imagens tratadas foi preparada uma função para gerar mais imagens usando aumento de dados, visto que o número de dados para trabalhar é pequeno e dentro dele já houve também um processo de aumento de dados. O objetivo dessa função é gerar imagens mais diferentes do que as que já foram geradas, usando uma rotação aleatória de 30 graus, permitindo uma inversão horizontal e variando o brilho e zoom na imagem. Além da mudança para gerar imagens novas, também foi aplicado o mesmo processamento da função anterior para padronizar as imagens. Feito o processamento as imagens são guardadas em outra pasta para validação futuramente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "political-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_augmented_images(folder, pictures):\n",
    "    print(\"Generate augmented images...\")\n",
    "    datagen = ImageDataGenerator(rotation_range=30, horizontal_flip=True, \n",
    "                                 brightness_range=[0.5, 1.0],\n",
    "                                 zoom_range=[0.5, 1.0])\n",
    "    for index, image in enumerate(pictures):\n",
    "        samples = expand_dims(img_to_array(image.img), 0)\n",
    "        augmented_image = datagen.flow(samples, batch_size=1).next()[0].astype('uint8')\n",
    "        cv2.imwrite(folder + image.name, augmented_image)\n",
    "\n",
    "        img = cv2.cvtColor(image.img, cv2.COLOR_BGR2GRAY)\n",
    "        suave = cv2.GaussianBlur(img, (7, 7), 0)\n",
    "        (T, binI) = cv2.threshold(suave, 105, 255, cv2.THRESH_BINARY_INV)\n",
    "        cv2.imwrite('Modified' + folder + image.name,\n",
    "                    cv2.bitwise_and(img, img, mask=binI))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-mouth",
   "metadata": {},
   "source": [
    "Por fim as funções anteriores são compactadas em uma função especifica para preparar os dados para que o algoritmo em si classifique-os."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "public-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(images_folder, modified_images_folder, augmented_images_folder):\n",
    "    print('Preparing data...')\n",
    "    images = load(images_folder)\n",
    "    process_and_save(modified_images_folder, images)\n",
    "    generate_augmented_images(augmented_images_folder, images)\n",
    "    print('Data prepared!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-paraguay",
   "metadata": {},
   "source": [
    "Feita as implementações inicias, o código declara variáveis globais de pastas para facilitar as configurações caso seja necessário e inicia com a preparação dos dados apresentada anteriormente. Caso o projeto já tenha sido baixado com as imagens processadas, esta função não precisa ser executada, mas caso seja, só irá fazer todo o processamento novamente e substituirá os dados. Após isso são definidas as constantes para o tamanho das imagens a serem treinadas, o tamanho do lote a ser processado, a semente para os dados randômicos e o tamanho da separação dos dados de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "silver-differential",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Loading images...\n",
      "Processing and saving images...\n",
      "Generate augmented images...\n",
      "Data prepared!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    images_folder = 'Images/'\n",
    "    modified_images_folder = 'ModifiedImages/'\n",
    "    augmented_images_folder = 'AugmentedImages/'\n",
    "    modified_augmented_images_folder = 'ModifiedAugmentedImages/'\n",
    "\n",
    "    prepare_data(images_folder, modified_images_folder, augmented_images_folder)\n",
    "\n",
    "    batch_size = 32\n",
    "    img_height = 180\n",
    "    img_width = 180\n",
    "    seed = 123\n",
    "    validation_split = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-emphasis",
   "metadata": {},
   "source": [
    "Então é feita a partição dos dados de treinamento usando as variáveis de configuração declaradas anteriormente. Também são salvos os nomes das classes que foram encontradas, para que seja possível comparar com os resultados ao validar o modelo. As classes são equivalentes as pastas em que os dados se encontram, por isso eles foram separados em duas pastas diferentes na preparação dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "valued-sterling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5460 files belonging to 2 classes.\n",
      "Using 4368 files for training.\n",
      "['Leukemia', 'Normal']\n"
     ]
    }
   ],
   "source": [
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        modified_images_folder,\n",
    "        validation_split=validation_split,\n",
    "        subset=\"training\",\n",
    "        seed=seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    class_names = train_ds.class_names\n",
    "    print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-external",
   "metadata": {},
   "source": [
    "Da mesma forma que foi feita a partição de treinamento também é feita a partição de validação dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "behavioral-evolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5460 files belonging to 2 classes.\n",
      "Using 1092 files for validation.\n"
     ]
    }
   ],
   "source": [
    "    val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        modified_images_folder,\n",
    "        validation_split=validation_split,\n",
    "        subset=\"validation\",\n",
    "        seed=seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-parent",
   "metadata": {},
   "source": [
    "Então é configurada uma otimização para o processamento, guardando dados em cache para acelerar a consulta e possibilitando que os dados futuros possam ser preparados enquanto os dados atuais estão sendo executados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "simplified-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-paste",
   "metadata": {},
   "source": [
    "Com as partições separadas são montadas as camadas que terão no modelo de classificação. Neste caso tendo 3 camadas de convolução 2D utilizando a função de ativação RELU, 3 camadas de agregação, 1 camada de dropout para ajudar a evitar overfitting, 1 camada de nivelamento e 2 camadas de densidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "colored-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = Sequential([\n",
    "        layers.experimental.preprocessing.Rescaling(1. / 255),\n",
    "        layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(2)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-particular",
   "metadata": {},
   "source": [
    "Em seguida o modelo é compilado utilizando o otimizador SGD, este usando a acurácia como parâmetro para definir os melhores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "global-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(optimizer='SGD',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-greene",
   "metadata": {},
   "source": [
    "Por fim o modelo é executado com 20 épocas, visto que o número de dados é pequeno e muitas épocas tendem a viciar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "drawn-tractor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing model...\n",
      "Epoch 1/20\n",
      "137/137 [==============================] - 236s 889ms/step - loss: 0.6369 - accuracy: 0.6459 - val_loss: 0.5190 - val_accuracy: 0.7088\n",
      "Epoch 2/20\n",
      "137/137 [==============================] - 104s 758ms/step - loss: 0.5027 - accuracy: 0.7378 - val_loss: 0.5099 - val_accuracy: 0.7326\n",
      "Epoch 3/20\n",
      "137/137 [==============================] - 103s 753ms/step - loss: 0.4775 - accuracy: 0.7653 - val_loss: 0.4877 - val_accuracy: 0.7234\n",
      "Epoch 4/20\n",
      "137/137 [==============================] - 104s 757ms/step - loss: 0.4595 - accuracy: 0.7644 - val_loss: 0.4683 - val_accuracy: 0.7445\n",
      "Epoch 5/20\n",
      "137/137 [==============================] - 103s 753ms/step - loss: 0.4339 - accuracy: 0.7803 - val_loss: 0.4285 - val_accuracy: 0.7802\n",
      "Epoch 6/20\n",
      "137/137 [==============================] - 104s 759ms/step - loss: 0.4230 - accuracy: 0.7886 - val_loss: 0.4121 - val_accuracy: 0.7985\n",
      "Epoch 7/20\n",
      "137/137 [==============================] - 107s 783ms/step - loss: 0.3912 - accuracy: 0.8138 - val_loss: 0.3958 - val_accuracy: 0.8077\n",
      "Epoch 8/20\n",
      "137/137 [==============================] - 105s 768ms/step - loss: 0.3701 - accuracy: 0.8229 - val_loss: 0.4480 - val_accuracy: 0.7775\n",
      "Epoch 9/20\n",
      "137/137 [==============================] - 104s 757ms/step - loss: 0.3446 - accuracy: 0.8461 - val_loss: 0.3578 - val_accuracy: 0.8297\n",
      "Epoch 10/20\n",
      "137/137 [==============================] - 104s 758ms/step - loss: 0.3517 - accuracy: 0.8379 - val_loss: 0.3457 - val_accuracy: 0.8288\n",
      "Epoch 11/20\n",
      "137/137 [==============================] - 104s 761ms/step - loss: 0.3327 - accuracy: 0.8433 - val_loss: 0.3403 - val_accuracy: 0.8361\n",
      "Epoch 12/20\n",
      "137/137 [==============================] - 104s 758ms/step - loss: 0.3110 - accuracy: 0.8552 - val_loss: 0.3330 - val_accuracy: 0.8361\n",
      "Epoch 13/20\n",
      "137/137 [==============================] - 104s 757ms/step - loss: 0.3018 - accuracy: 0.8616 - val_loss: 0.3226 - val_accuracy: 0.8407\n",
      "Epoch 14/20\n",
      "137/137 [==============================] - 104s 760ms/step - loss: 0.2990 - accuracy: 0.8593 - val_loss: 0.3651 - val_accuracy: 0.8205\n",
      "Epoch 15/20\n",
      "137/137 [==============================] - 104s 758ms/step - loss: 0.2740 - accuracy: 0.8764 - val_loss: 0.3985 - val_accuracy: 0.8196\n",
      "Epoch 16/20\n",
      "137/137 [==============================] - 103s 755ms/step - loss: 0.2668 - accuracy: 0.8767 - val_loss: 0.3148 - val_accuracy: 0.8507\n",
      "Epoch 17/20\n",
      "137/137 [==============================] - 104s 756ms/step - loss: 0.2483 - accuracy: 0.8969 - val_loss: 0.3121 - val_accuracy: 0.8471\n",
      "Epoch 18/20\n",
      "137/137 [==============================] - 104s 758ms/step - loss: 0.2445 - accuracy: 0.8915 - val_loss: 0.3093 - val_accuracy: 0.8434\n",
      "Epoch 19/20\n",
      "137/137 [==============================] - 103s 752ms/step - loss: 0.2384 - accuracy: 0.8955 - val_loss: 0.2924 - val_accuracy: 0.8581\n",
      "Epoch 20/20\n",
      "137/137 [==============================] - 104s 763ms/step - loss: 0.2195 - accuracy: 0.9024 - val_loss: 0.3028 - val_accuracy: 0.8553\n",
      "Model done!\n"
     ]
    }
   ],
   "source": [
    "    print('Executing model...')\n",
    "    epochs = 20\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs\n",
    "    )\n",
    "    print('Model done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-camel",
   "metadata": {},
   "source": [
    "Então valida o modelo com a partição de treinamento e o salva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "arbitrary-breath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 27s 198ms/step - loss: 0.1881 - accuracy: 0.9302\n",
      "INFO:tensorflow:Assets written to: LeukemiaModel\\assets\n"
     ]
    }
   ],
   "source": [
    "    results = model.evaluate(train_ds, batch_size=128)\n",
    "\n",
    "    model.save('LeukemiaModel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-position",
   "metadata": {},
   "source": [
    "Por fim tenta fazer as predições do utilizando as imagens já tratadas geradas pela função de aumento de dados, e contabiliza os resultados comparando com o que foi obtido na validação anterior do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "looking-blind",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting images...\n",
      "Test loss: 18.81%; Test accuracy: 93.02%.\n",
      "This model had 91.12% accuracy on augmented images.\n"
     ]
    }
   ],
   "source": [
    "    print('Predicting images...')\n",
    "    num_img, num_score = 0, 0\n",
    "    for index, filename in enumerate(\n",
    "        os.listdir(modified_augmented_images_folder)):\n",
    "        img = os.path.join(\n",
    "            modified_augmented_images_folder, filename)\n",
    "        img = kerasImage.load_img(\n",
    "            img, target_size=(img_width, img_height))\n",
    "        img = kerasImage.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "\n",
    "        image = Image(filename, img, filename[-5])\n",
    "\n",
    "        predictions = model.predict(image.img)\n",
    "        score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "        if (class_names[np.argmax(score)] == \"Leukemia\" \n",
    "            and image.type == '1') or (\n",
    "                class_names[np.argmax(score)] == \"Normal\" \n",
    "            and image.type == '0'):\n",
    "            num_score += 1\n",
    "\n",
    "        num_img += 1\n",
    "\n",
    "    print(\"Test loss: {:.2f}%; Test accuracy: {:.2f}%.\"\n",
    "          .format(results[0] * 100, results[1] * 100))\n",
    "    print('This model had {:.2f}% accuracy on augmented images.'\n",
    "          .format(0 if num_score == 0 else num_score * 100 / num_img))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
