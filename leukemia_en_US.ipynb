{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "recent-stage",
   "metadata": {},
   "source": [
    "# Leukemia detection based on leukocyte images\n",
    "\n",
    "This project was developed for the final work of the Computer Vision course, taught by Prof. Dr. Lucas Ferrari de Oliveira for the Specialization Course in Applied Artificial Intelligence at the Federal University of Paran√°.\n",
    "\n",
    "#### Project description\n",
    "\n",
    "The trabalho.zip file has leukocyte images in the central part. The images are named as \"ImXXX_Y_Z.jpg\". Where ImXXX is the number of the image, Y is its number of the sequence of alteration (data augmentation) and Z its class (0 or 1). Where, 0 indicates a normal patient and 1 indicates leukemia.\n",
    "\n",
    "Using Computer Vision and/or CNNS techniques, extract characteristics from the images and make their correct classification (0 or 1). Remember to separate the training and testing groups. You can use the k-fold technique to divide the images and avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-reception",
   "metadata": {},
   "source": [
    "### Steps to run the code\n",
    "\n",
    "You need to have a Python environment set up on your machine to run the code. It was developed on Python 3.8, so this is the most recommended version to run.\n",
    "\n",
    "<b> In addition to the Python environment, give preference to running this Notebook in Jupyter Labs. Running on Jupyter Notebooks the console output will only appear on your Python terminal and not on the Notebook. </b>\n",
    "\n",
    "Beside the environment, some libraries will be needed for the code:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;- Numpy (https://numpy.org/) (1.19.0)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;- OpenCV (https://opencv.org/) (4.5.1.48)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;- Tensorflow (https://www.tensorflow.org/) (2.2)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;- Keras (https://keras.io/) (2.3.1)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;- ScyPy (https://www.scipy.org/) (1.6.0)<br>\n",
    "    \n",
    "If necessary, I can pass my PyCharm venv environment with these packages already installed.\n",
    "\n",
    "The folder structure of the images must be in the following hierarchy: <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;- Root <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- AugmentedImages <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Images <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- ModifiedAugmentedImages <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- ModifiedImages <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Leukemia <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Normal <br>\n",
    "\n",
    "In addition, the code must be at the root folder for it to run correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-spencer",
   "metadata": {},
   "source": [
    "<b> Installing libraries on the Python terminal (PIP) </b><br>\n",
    "pip install numpy <br>\n",
    "pip install opencv-python <br>\n",
    "pip install tensorflow <br>\n",
    "pip install matplotlib <br>\n",
    "pip install SciPy <br>\n",
    "\n",
    "<b> Installation of libraries in Conda environment (not tested) </b><br>\n",
    "conda install numpy <br>\n",
    "conda install -c menpo opencv <br>\n",
    "conda create -n tf tensorflow <br>\n",
    "conda activate tf <br>\n",
    "conda install -c anaconda scipy <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-motorcycle",
   "metadata": {},
   "source": [
    "## Code description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-regulation",
   "metadata": {},
   "source": [
    "Initially it is necessary to import all packages that will be used within the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sound-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image as kerasImage\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-sacramento",
   "metadata": {},
   "source": [
    "Then a class is created to store the image data, such as the image in question, its file name and its type, with 1 representing the leukocyte with leukemia and 0 for the normal leukocyte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "medieval-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image:\n",
    "    img = None\n",
    "    name = ''\n",
    "    type = ''\n",
    "\n",
    "    def __init__(self, name, img, type):\n",
    "        self.name = name\n",
    "        self.img = img\n",
    "        self.type = type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-command",
   "metadata": {},
   "source": [
    "With the created class it is now possible to create a function that reads a directory, takes images, their file names and within the file name extract the right type of each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "stylish-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(folder):\n",
    "    print(\"Loading images...\")\n",
    "    pictures = []\n",
    "    for filename in enumerate(os.listdir(folder)):\n",
    "        pictures.append(Image(filename[1], cv2.imread(os.path.join(folder, filename[1])), filename[1][-5]))\n",
    "    return pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-fabric",
   "metadata": {},
   "source": [
    "Having a list of images it is possible to process them and save them in another directory to use them in the future for the training execution. For this process a light Gaussian blur was applied to decrease the image noise, and then a simple inverted binary threshold was applied. This threshold is applied to the entire image, so if the pixel is smaller than the threshold, it is passed to the maximum value, otherwise it is passed to zero. Then this binary image is saved as a mask and applied on top of the original image, aiming to isolate only the leukocyte in the central part. Once it is done, the images are separated into two different folders, one for normal cases and another for leukemia cases. It is separated in this way so that it is possible to separate it further into classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "racial-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save(folder, pictures):\n",
    "    print(\"Processing and saving images...\")\n",
    "    for index, image in enumerate(pictures):\n",
    "        img = cv2.cvtColor(image.img, cv2.COLOR_BGR2GRAY)\n",
    "        suave = cv2.GaussianBlur(img, (7, 7), 0)\n",
    "        (T, binI) = cv2.threshold(suave, 105, 255, cv2.THRESH_BINARY_INV)\n",
    "        subfolder = folder + 'Leukemia/' if image.type == '1' else folder + 'Normal/'\n",
    "        cv2.imwrite(subfolder + image.name,\n",
    "                    cv2.bitwise_and(img, img, mask=binI))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-helicopter",
   "metadata": {},
   "source": [
    "In addition to the treated images, a function was prepared to generate more images using data augmentation, since the number of data to work with is small and within it there has also been a data augmentation process. The purpose of this function is to generate images that are more different than those that have already been generated, using a random 30 degrees rotation, allowing horizontal flip and varying the brightness and zoom in the image. Besides to the change to generate new images, the same process as the previous function was also applied to standardize the images. After processing, the images are saved in another folder for future validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "backed-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_augmented_images(folder, pictures):\n",
    "    print(\"Generate augmented images...\")\n",
    "    datagen = ImageDataGenerator(rotation_range=30, horizontal_flip=True, brightness_range=[0.5, 1.0],\n",
    "                                 zoom_range=[0.5, 1.0])\n",
    "    for index, image in enumerate(pictures):\n",
    "        samples = expand_dims(img_to_array(image.img), 0)\n",
    "        augmented_image = datagen.flow(samples, batch_size=1).next()[0].astype('uint8')\n",
    "        cv2.imwrite(folder + image.name, augmented_image)\n",
    "\n",
    "        img = cv2.cvtColor(image.img, cv2.COLOR_BGR2GRAY)\n",
    "        suave = cv2.GaussianBlur(img, (7, 7), 0)\n",
    "        (T, binI) = cv2.threshold(suave, 105, 255, cv2.THRESH_BINARY_INV)\n",
    "        cv2.imwrite('Modified' + folder + image.name,\n",
    "                    cv2.bitwise_and(img, img, mask=binI))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-senior",
   "metadata": {},
   "source": [
    "Finally, the previous functions are compacted in a specific function to prepare the data so that the algorithm itself classifies them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "changed-fleet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(images_folder, modified_images_folder, augmented_images_folder):\n",
    "    print('Preparing data...')\n",
    "    images = load(images_folder)\n",
    "    process_and_save(modified_images_folder, images)\n",
    "    generate_augmented_images(augmented_images_folder, images)\n",
    "    print('Data prepared!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-actor",
   "metadata": {},
   "source": [
    "Having made the initial implementations, the code declares global folder variables to facilitate the configurations if necessary and starts with the preparation of the data presented previously. If the project has already been downloaded with the processed images, this function does not need to be executed, but if it is, it will only do all the process again and replace the data. After that, the constants are defined for the size of the images to be trained, the size of the batch to be processed, the seed for the random data and the size for the separation of the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "automotive-combine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Loading images...\n",
      "Processing and saving images...\n",
      "Generate augmented images...\n",
      "Data prepared!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    images_folder = 'Images/'\n",
    "    modified_images_folder = 'ModifiedImages/'\n",
    "    augmented_images_folder = 'AugmentedImages/'\n",
    "    modified_augmented_images_folder = 'ModifiedAugmentedImages/'\n",
    "\n",
    "    prepare_data(images_folder, modified_images_folder, augmented_images_folder)\n",
    "\n",
    "    batch_size = 32\n",
    "    img_height = 180\n",
    "    img_width = 180\n",
    "    seed = 123\n",
    "    validation_split = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-bottle",
   "metadata": {},
   "source": [
    "Then the training data is partitioned using the configuration variables declared earlier. The names of the classes that were found are also saved, so that it is possible to compare with the results when validating the model. The classes are equivalent to the folders in which the data are located, so they were separated into two different folders in the preparation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "victorian-agenda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5460 files belonging to 2 classes.\n",
      "Using 4368 files for training.\n",
      "['Leukemia', 'Normal']\n"
     ]
    }
   ],
   "source": [
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        modified_images_folder,\n",
    "        validation_split=validation_split,\n",
    "        subset=\"training\",\n",
    "        seed=seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    class_names = train_ds.class_names\n",
    "    print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-cooperation",
   "metadata": {},
   "source": [
    "In the same way that the training partition was made, so is the data validation partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "starting-subscriber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5460 files belonging to 2 classes.\n",
      "Using 1092 files for validation.\n"
     ]
    }
   ],
   "source": [
    "    val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        modified_images_folder,\n",
    "        validation_split=validation_split,\n",
    "        subset=\"validation\",\n",
    "        seed=seed,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-pierce",
   "metadata": {},
   "source": [
    "Then an optimization is configured for processing, caching data to speed up the query and enabling future data to be prepared while the current data is being executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "august-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-relation",
   "metadata": {},
   "source": [
    "With the separate partitions, the layers they will have in the classification model are assembled. In this case having 3 layers of 2D convolution using the RELU activation function, 3 pooling layers, 1 dropout layer to help prevent overfitting, 1 flatten layer and 2 density layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "committed-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = Sequential([\n",
    "        layers.experimental.preprocessing.Rescaling(1. / 255),\n",
    "        layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(2)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-exclusive",
   "metadata": {},
   "source": [
    "Then the model is compiled using the SGD optimizer, which uses accuracy as a parameter to define the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "blind-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(optimizer='SGD',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-ethnic",
   "metadata": {},
   "source": [
    "Finally, the model runs with 20 epochs, since the number of data is small and many epochs tend to overfit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "unlimited-vegetable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing model...\n",
      "Epoch 1/20\n",
      "137/137 [==============================] - 236s 889ms/step - loss: 0.6369 - accuracy: 0.6459 - val_loss: 0.5190 - val_accuracy: 0.7088\n",
      "Epoch 2/20\n",
      "137/137 [==============================] - 104s 758ms/step - loss: 0.5027 - accuracy: 0.7378 - val_loss: 0.5099 - val_accuracy: 0.7326\n",
      "Epoch 3/20\n",
      "137/137 [==============================] - 103s 753ms/step - loss: 0.4775 - accuracy: 0.7653 - val_loss: 0.4877 - val_accuracy: 0.7234\n",
      "Epoch 4/20\n",
      "137/137 [==============================] - 104s 757ms/step - loss: 0.4595 - accuracy: 0.7644 - val_loss: 0.4683 - val_accuracy: 0.7445\n",
      "Epoch 5/20\n",
      "137/137 [==============================] - 103s 753ms/step - loss: 0.4339 - accuracy: 0.7803 - val_loss: 0.4285 - val_accuracy: 0.7802\n",
      "Epoch 6/20\n",
      "137/137 [==============================] - 104s 759ms/step - loss: 0.4230 - accuracy: 0.7886 - val_loss: 0.4121 - val_accuracy: 0.7985\n",
      "Epoch 7/20\n",
      "137/137 [==============================] - 107s 783ms/step - loss: 0.3912 - accuracy: 0.8138 - val_loss: 0.3958 - val_accuracy: 0.8077\n",
      "Epoch 8/20\n",
      "137/137 [==============================] - 105s 768ms/step - loss: 0.3701 - accuracy: 0.8229 - val_loss: 0.4480 - val_accuracy: 0.7775\n",
      "Epoch 9/20\n",
      "137/137 [==============================] - 104s 757ms/step - loss: 0.3446 - accuracy: 0.8461 - val_loss: 0.3578 - val_accuracy: 0.8297\n",
      "Epoch 10/20\n",
      "137/137 [==============================] - 104s 758ms/step - loss: 0.3517 - accuracy: 0.8379 - val_loss: 0.3457 - val_accuracy: 0.8288\n",
      "Epoch 11/20\n",
      "137/137 [==============================] - 104s 761ms/step - loss: 0.3327 - accuracy: 0.8433 - val_loss: 0.3403 - val_accuracy: 0.8361\n",
      "Epoch 12/20\n",
      "137/137 [==============================] - 104s 758ms/step - loss: 0.3110 - accuracy: 0.8552 - val_loss: 0.3330 - val_accuracy: 0.8361\n",
      "Epoch 13/20\n",
      "137/137 [==============================] - 104s 757ms/step - loss: 0.3018 - accuracy: 0.8616 - val_loss: 0.3226 - val_accuracy: 0.8407\n",
      "Epoch 14/20\n",
      "137/137 [==============================] - 104s 760ms/step - loss: 0.2990 - accuracy: 0.8593 - val_loss: 0.3651 - val_accuracy: 0.8205\n",
      "Epoch 15/20\n",
      "137/137 [==============================] - 104s 758ms/step - loss: 0.2740 - accuracy: 0.8764 - val_loss: 0.3985 - val_accuracy: 0.8196\n",
      "Epoch 16/20\n",
      "137/137 [==============================] - 103s 755ms/step - loss: 0.2668 - accuracy: 0.8767 - val_loss: 0.3148 - val_accuracy: 0.8507\n",
      "Epoch 17/20\n",
      "137/137 [==============================] - 104s 756ms/step - loss: 0.2483 - accuracy: 0.8969 - val_loss: 0.3121 - val_accuracy: 0.8471\n",
      "Epoch 18/20\n",
      "137/137 [==============================] - 104s 758ms/step - loss: 0.2445 - accuracy: 0.8915 - val_loss: 0.3093 - val_accuracy: 0.8434\n",
      "Epoch 19/20\n",
      "137/137 [==============================] - 103s 752ms/step - loss: 0.2384 - accuracy: 0.8955 - val_loss: 0.2924 - val_accuracy: 0.8581\n",
      "Epoch 20/20\n",
      "137/137 [==============================] - 104s 763ms/step - loss: 0.2195 - accuracy: 0.9024 - val_loss: 0.3028 - val_accuracy: 0.8553\n",
      "Model done!\n"
     ]
    }
   ],
   "source": [
    "    print('Executing model...')\n",
    "    epochs = 20\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs\n",
    "    )\n",
    "    print('Model done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-couple",
   "metadata": {},
   "source": [
    "Then validate the model with the training partition and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "exempt-attraction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 27s 198ms/step - loss: 0.1881 - accuracy: 0.9302\n",
      "INFO:tensorflow:Assets written to: LeukemiaModel\\assets\n"
     ]
    }
   ],
   "source": [
    "    results = model.evaluate(train_ds, batch_size=128)\n",
    "\n",
    "    model.save('LeukemiaModel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-jonathan",
   "metadata": {},
   "source": [
    "Finally, it tries to make the predictions using the treated images generated by the data augmentation function, and counts the results in comparison with what was obtained in the previous model validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "theoretical-import",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting images...\n",
      "Test loss: 18.81%; Test accuracy: 93.02%.\n",
      "This model had 91.12% accuracy on augmented images.\n"
     ]
    }
   ],
   "source": [
    "    print('Predicting images...')\n",
    "    num_img, num_score = 0, 0\n",
    "    for index, filename in enumerate(os.listdir(modified_augmented_images_folder)):\n",
    "        img = os.path.join(modified_augmented_images_folder, filename)\n",
    "        img = kerasImage.load_img(img, target_size=(img_width, img_height))\n",
    "        img = kerasImage.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "\n",
    "        image = Image(filename, img, filename[-5])\n",
    "\n",
    "        predictions = model.predict(image.img)\n",
    "        score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "        if (class_names[np.argmax(score)] == \"Leukemia\" and image.type == '1') or (\n",
    "                class_names[np.argmax(score)] == \"Normal\" and image.type == '0'):\n",
    "            num_score += 1\n",
    "\n",
    "        num_img += 1\n",
    "\n",
    "    print(\"Test loss: {:.2f}%; Test accuracy: {:.2f}%.\".format(results[0] * 100, results[1] * 100))\n",
    "    print('This model had {:.2f}% accuracy on augmented images.'.format(\n",
    "        0 if num_score == 0 else num_score * 100 / num_img))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
